{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tables as tb\n",
    "write_path = 'test_tables.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to flush\n",
    "\n",
    "Our data consist of many events. For each event, we have 5 different signals we want to append to 5 different pytables. The number of rows we append to each pytable varies from signal to signal and event to event.     \n",
    "\n",
    "\n",
    "This is a simplified representation of how we have implemented our table writers and an experimental investigation into when to flush."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Signal(tb.IsDescription):\n",
    "    event    = tb.  Int32Col()\n",
    "    time     = tb.Float32Col()\n",
    "    energy   = tb.Float32Col()\n",
    "    \n",
    "filt = tb.Filters()\n",
    "\n",
    "def create_n_pytables(num_tables, h5out, group):\n",
    "    \"\"\"\n",
    "    create num_tables pytables in group. \n",
    "    tables are accessible via group.ti where i is in range num_tables\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    for i in range(num_tables):\n",
    "        path = 't{}'     .format(i)\n",
    "        name = 'Table  {}'.format(i)\n",
    "        tables.append(h5out.create_table(group, path, Signal, name, filt))\n",
    "        tables[-1].cols.event.create_index()\n",
    "    return tables\n",
    "    \n",
    "def toy_signal():\n",
    "    \"\"\"\n",
    "    makes a toy signal (time, energy),\n",
    "    where time and energy are 1d np.ndarrays of equal but\n",
    "    random length, between, minl and maxl\n",
    "    \"\"\"\n",
    "    minl = 10; maxl = 100\n",
    "    signal_length = np.random.randint(minl, high=maxl)\n",
    "    t = np.arange(signal_length, dtype=np.float32)\n",
    "    e = np.random.random(signal_length)\n",
    "    return t, e\n",
    "\n",
    "def write_signal_for_one_event(table, event, toy_signal, flush_0=False):\n",
    "    for t, e in zip(*toy_signal):\n",
    "        table.row[\"event\"]  = event\n",
    "        table.row[\"time\"]   = t\n",
    "        table.row[\"energy\"] = e\n",
    "        table.row.append()\n",
    "        \n",
    "    if flush_0: table.flush() # Should we flush here? \n",
    "                              # Sometimes? Always?\n",
    "                              # Pytables documentation seems to  \n",
    "                              # recommend flushing here.\n",
    "                              # But we have never run into problems \n",
    "                              # without this flush, and flushing,\n",
    "                              # at least with our implementation, \n",
    "                              # slows things down a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_some_pytables(write_path, \n",
    "                        num_tables =  5,   # Number of tables to write\n",
    "                        num_events =100,   # Number of events\n",
    "                        flush_0 = False,   # Flush each table for each event \n",
    "                        flush_1 = False):  # Flush file before closing the file\n",
    "    \n",
    "    with tb.open_file(write_path, 'w') as h5out:\n",
    "        g1 = h5out.create_group(h5out.root, 'g1')         # Make group\n",
    "        tables = create_n_pytables(num_tables, h5out, g1) # Make num_tables in group\n",
    "\n",
    "        for event in range(num_events): # For each event,\n",
    "            for table in tables:        # Write a toy signal to its table.\n",
    "                write_signal_for_one_event(table, \n",
    "                                           event, \n",
    "                                           toy_signal(), \n",
    "                                           flush_0=flush_0)\n",
    "                \n",
    "        if flush_1: h5out.flush() \n",
    "        # Should we flush the entire file here? When we don't do this\n",
    "        # we frequently end up with blank pytables.\n",
    "        #\n",
    "        # It's strange flushing here changes anything, since the file closes \n",
    "        # immediately after this line is executed, and pytables documentation\n",
    "        # says a file is flushed automatically as it closes....     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Flushing\n",
    "For the rest of this notebook we create and write events to pytables, experimenting with when and where to flush.    \n",
    "\n",
    "As a sort of benchmark, in most of these cells I set `num_events` to be 100k. This is excessively large. In NEXT the number of detector data events we write to one file is usually less than 200, and the number of monte carlo events we write to one file typically does not exceed 100k. By using such a large number of events in this mini-study, hopefully we can have a little confidence that if we don't see losses of data here, we will not lose any events in our actual data processing.\n",
    "\n",
    "First, notice that for up to 4 signals / event (4 pytables) we do not lose any data, even if we do no flushing. (I've checked this with `num_tables` also set to 1, 2, and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.8 s, sys: 536 ms, total: 40.3 s\n",
      "Wall time: 40.8 s\n",
      "fraction of events succesfully written: 1.0 in t0\n",
      "fraction of events succesfully written: 1.0 in t1\n",
      "fraction of events succesfully written: 1.0 in t2\n",
      "fraction of events succesfully written: 1.0 in t3\n"
     ]
    }
   ],
   "source": [
    "num_events = 100000; num_tables = 4\n",
    "%time write_some_pytables(write_path, num_tables=num_tables, num_events=num_events, flush_0=False, flush_1=False)\n",
    "\n",
    "with tb.open_file(write_path, 'r') as f: \n",
    "    for table in f.root.g1: # Ensure each pytable has num_events events\n",
    "        print('fraction of events succesfully written:', \n",
    "              len(set(table[:]['event'])) / num_events, 'in', table.name) # python 3 division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we if flush after every event, it's about 35 times slower per event, so we don't want to do that. Notice, I've decreased the num_events to 1k so that it is not so time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 663 ms, total: 15.6 s\n",
      "Wall time: 15.7 s\n",
      "fraction of events succesfully written: 1.0 in t0\n",
      "fraction of events succesfully written: 1.0 in t1\n",
      "fraction of events succesfully written: 1.0 in t2\n",
      "fraction of events succesfully written: 1.0 in t3\n"
     ]
    }
   ],
   "source": [
    "num_events = 1000; num_tables = 4\n",
    "%time write_some_pytables(write_path, num_tables=num_tables, num_events=num_events, flush_0=True, flush_1=False)\n",
    "\n",
    "with tb.open_file(write_path, 'r') as f: \n",
    "    for table in f.root.g1:\n",
    "        print('fraction of events succesfully written:', \n",
    "              len(set(table[:]['event'])) / num_events, 'in', table.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, if we increase the number of tables to 5, even with only 1 event, one of the pytables is lost if we do not flush.        \n",
    "After some experimenting, its seems to consistently be whichever table had this line run first: `tables[-1].cols.event.create_index()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.8 ms, sys: 24.7 ms, total: 66.5 ms\n",
      "Wall time: 64.7 ms\n",
      "fraction of events succesfully written: 0.0\n",
      "fraction of events succesfully written: 1.0\n",
      "fraction of events succesfully written: 1.0\n",
      "fraction of events succesfully written: 1.0\n",
      "fraction of events succesfully written: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <object repr() failed>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alej/miniconda/envs/IC3.6/lib/python3.6/site-packages/tables/node.py\", line 321, in __del__\n",
      "    self._f_close()\n",
      "  File \"/Users/alej/miniconda/envs/IC3.6/lib/python3.6/site-packages/tables/table.py\", line 2957, in _f_close\n",
      "    self.flush()\n",
      "  File \"/Users/alej/miniconda/envs/IC3.6/lib/python3.6/site-packages/tables/table.py\", line 2891, in flush\n",
      "    self.row._flush_buffered_rows()\n",
      "  File \"tables/tableextension.pyx\", line 1333, in tables.tableextension.Row._flush_buffered_rows (tables/tableextension.c:16357)\n",
      "  File \"tables/tableextension.pyx\", line 749, in tables.tableextension.Row.table.__get__ (tables/tableextension.c:9587)\n",
      "  File \"/Users/alej/miniconda/envs/IC3.6/lib/python3.6/site-packages/tables/file.py\", line 2101, in _check_open\n",
      "    raise ClosedFileError(\"the file object is closed\")\n",
      "tables.exceptions.ClosedFileError: the file object is closed\n"
     ]
    }
   ],
   "source": [
    "num_events = 1; num_tables = 5\n",
    "%time write_some_pytables(write_path, num_tables=num_tables, num_events=num_events, flush_0=False, flush_1=False)\n",
    "with tb.open_file(write_path, 'r') as f: \n",
    "    for table in f.root.g1:\n",
    "        print('fraction of events succesfully written:', \n",
    "              len(set(table[:]['event'])) / num_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve the problem in the cell above if we **flush the entire file once just before closing it.**    \n",
    "We don't lose any tables/events even when we increase `num_tables` to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 42s, sys: 1.33 s, total: 1min 44s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "num_events = 100000; num_tables = 10\n",
    "%time write_some_pytables(write_path, num_tables=num_tables, num_events=num_events, flush_0=False, flush_1=True)\n",
    "with tb.open_file(write_path, 'r') as f: \n",
    "    for table in f.root.g1:\n",
    "        assert len(set(table[:]['event'])) ==  num_events # Just assert that all events were written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, flushing once just before closing the write file does not slow things down significantly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File flushed just before closing it.\n",
      "CPU times: user 40.1 s, sys: 572 ms, total: 40.6 s\n",
      "Wall time: 41.3 s\n",
      "--------\n",
      "No flush\n",
      "CPU times: user 39.8 s, sys: 571 ms, total: 40.4 s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "num_events = 100000; num_tables = 4\n",
    "print('File flushed just before closing it.')\n",
    "%time write_some_pytables(write_path, num_tables=num_tables, num_events=num_events, flush_0=False, flush_1=True)\n",
    "with tb.open_file(write_path, 'r') as f: \n",
    "    for table in f.root.g1: \n",
    "        assert len(set(table[:]['event'])) ==  num_events\n",
    "print('--------')     \n",
    "print('No flush')\n",
    "%time write_some_pytables(write_path, num_tables=num_tables, num_events=num_events, flush_0=False, flush_1=False)\n",
    "with tb.open_file(write_path, 'r') as f: \n",
    "    for table in f.root.g1:\n",
    "        assert len(set(table[:]['event'])) ==  num_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Primarily, this mini-study suggests that with our implementation, **flushing the entire file once just before closing it should be sufficient to prevent any loss in data, without suffering a meaningful loss in speed**.\n",
    "\n",
    "Some additional notes are:    \n",
    "\n",
    "- Danger of losing data seems to increase as we increase the number of tables we write simultaneously, and not as we increase the number of events we write in total. Even when I increased `num_events` to 1,000,000 (Not shown here) we did not lose any events with 1 pytable and no flushes. I did not try with more than 1 pytable because it is time consuming.    \n",
    "\n",
    "\n",
    "- Pytables seems to be exhibiting some unexpected behavior when we write more than 4 tables: It raises a strange, ignored exception when we do not flush manually before closing the file. I say flush 'manually' because I think the file should flush automatically before closing. Pytables doc says for `h5out.close()`: \"Flush all the alive leaves in object tree and close the file\" and for `h5out.flush()`: \"Flush all the alive leaves in the object tree.\" So, when we have 5+ pytables, and we don't flush manually, the strange exception is h5out trying to flush but failing as it closes, I think. A consequence of this behavior, is that afterwards the file seems not to have been closed properly. I cannot reopen the file in 'w' write mode until I clear the `Restart & Clear Output` the notebook. See below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that **the last cell run up to this point -cell [8]- is the cell that lost a table**, attempting to write 5 tables with no flushes. Now, i cannot reopen `write_file` in 'w' mode without restarting the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_tables.h5 (File) ''\n",
      "Last modif.: 'Sat Sep  2 16:12:47 2017'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/g1 (Group) ''\n",
      "/g1/t0 (Table(0,)) 'Table  0'\n",
      "/g1/t1 (Table(32,)) 'Table  1'\n",
      "/g1/t2 (Table(36,)) 'Table  2'\n",
      "/g1/t3 (Table(34,)) 'Table  3'\n",
      "/g1/t4 (Table(65,)) 'Table  4'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tb.open_file(write_path,  'r') as f: print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_tables.h5 (File) ''\n",
      "Last modif.: 'Sat Sep  2 16:12:47 2017'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/g1 (Group) ''\n",
      "/g1/t0 (Table(0,)) 'Table  0'\n",
      "/g1/t1 (Table(32,)) 'Table  1'\n",
      "/g1/t2 (Table(36,)) 'Table  2'\n",
      "/g1/t3 (Table(34,)) 'Table  3'\n",
      "/g1/t4 (Table(65,)) 'Table  4'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tb.open_file(write_path, 'r+') as f: print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_tables.h5 (File) ''\n",
      "Last modif.: 'Sat Sep  2 16:12:47 2017'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/g1 (Group) ''\n",
      "/g1/t0 (Table(0,)) 'Table  0'\n",
      "/g1/t1 (Table(32,)) 'Table  1'\n",
      "/g1/t2 (Table(36,)) 'Table  2'\n",
      "/g1/t3 (Table(34,)) 'Table  3'\n",
      "/g1/t4 (Table(65,)) 'Table  4'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tb.open_file(write_path,  'a') as f: print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"H5F.c\", line 522, in H5Fcreate\n    unable to create file\n  File \"H5Fint.c\", line 1024, in H5F_open\n    unable to truncate a file which is already open\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'test_tables.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e85e7e21ba4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_path\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/alej/miniconda/envs/IC3.6/lib/python3.6/site-packages/tables/file.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alej/miniconda/envs/IC3.6/lib/python3.6/site-packages/tables/file.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new (tables/hdf5extension.c:5943)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mHDF5ExtError\u001b[0m: HDF5 error back trace\n\n  File \"H5F.c\", line 522, in H5Fcreate\n    unable to create file\n  File \"H5Fint.c\", line 1024, in H5F_open\n    unable to truncate a file which is already open\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'test_tables.h5'"
     ]
    }
   ],
   "source": [
    "with tb.open_file(write_path,  'w') as f: print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
